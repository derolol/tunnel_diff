data:
  target: dataset.data_module.DataModule
  params:
    # Path to training set configuration file.
    train_config: config/dataset/exposure_errors_b16_train.yaml
    # Path to validation set configuration file.
    val_config: config/dataset/exposure_errors_val.yaml

model:
  target: model.tunnel_diff.tunnel_diff_module.TunnelDiffModule
  checkpoint: weight/tunnel_diff/train/step=20000.ckpt
  params:
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: "jpg"
    cond_stage_key: "txt"
    control_key: "hint"
    image_size: 64
    channels: 4
    cond_stage_trainable: false
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_factor: 0.18215
    use_ema: False
    
    sd_locked: True
    only_mid_control: False
    # Learning rate.
    learning_rate: 1e-4

    sample_light: 200
    
    control_stage_config:
      target: model.tunnel_diff.tunnel_diff.ControlNet
      params:
        use_checkpoint: True
        image_size: 32 # unused
        in_channels: 4
        hint_channels: 8
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_head_channels: 64 # need to fix for flash-attn
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 128
        legacy: False

    unet_config:
      target: model.tunnel_diff.tunnel_diff.ControlledUnetModel
      params:
        use_checkpoint: True
        image_size: 32 # unused
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_head_channels: 64 # need to fix for flash-attn
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 128
        legacy: False

    first_stage_config:
      target: model.tunnel_diff.ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          #attn_type: "vanilla-xformers"
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    cond_stage_config:
      target: model.tunnel_diff.ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder
      params:
        freeze: True
        layer: "penultimate"

lightning:
  seed: 231
  
  trainer:
    accelerator: cuda
    precision: 32
    strategy: ddp_find_unused_parameters_true
    # Indices of GPUs used for training.
    devices: 4
    # Path to save logs and checkpoints.
    default_root_dir: outputs
    # Max number of training steps (batches).
    max_steps: 25001
    # Validation frequency in terms of training steps.
    val_check_interval: 500
    check_val_every_n_epoch:
    log_every_n_steps: 50
    # Accumulate gradients from multiple batches so as to increase batch size.
    accumulate_grad_batches: 4
  
  logger:
    # target: logger.wandb.WandbLogger
    # params:
    #   name: 
    #   project: aug_seg
    #   offline: True
    #   settings:
    #     init_timeout: 100
    target: logger.tensorboard.TensorBoardLogger
    params:
      save_dir: test_viz
      name: tunnel_diff_exposure_errors_200
  
  callbacks:
    - target: model.callbacks.ImageLogger
      params:
        # Log frequency of image logger.
        log_every_n_steps: 100
        max_images_each_step: 4
        log_images_kwargs: ~

    - target: model.callbacks.ModelCheckpoint
      params:
        # Frequency of saving checkpoints.
        every_n_train_steps: 5000
        save_top_k: -1
        filename: "{step}"
